% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  12pt,
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Détection de fraudes et loi de probabilité de Newcomb-Benford},
  pdfauthor={FERNANDEZ Christelle; PONCHEELE Clément; EL KAÏM Laura; Encadré par M.DUCHARME},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\oddsidemargin -1cm
\textwidth 18,5cm
\textheight 24cm
\usepackage{caption}
\captionsetup[table]{labelformat=empty}
\captionsetup[figure]{labelformat=empty}
\usepackage[french]{babel}
\setcounter{page}{0}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{\textbf{Détection de fraudes et loi de probabilité de
Newcomb-Benford}}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Projet Master \(1\)}
\author{FERNANDEZ Christelle \and PONCHEELE Clément \and EL KAÏM
Laura \and Encadré par M.DUCHARME}
\date{\emph{\(24\) mai \(2021\)}}

\begin{document}
\maketitle

\newpage
\setcounter{page}{0}
\thispagestyle{empty}

\begin{center}\includegraphics[width=2\linewidth]{Images/page_de_garde} \end{center}

\newpage
\pagenumbering{roman}

\hypertarget{remerciements}{%
\section{Remerciements}\label{remerciements}}

~ Nous souhaitons remercier la faculté des Sciences de Montpellier pour
les Master MIND (Mathématiques de l'Information et de la Décision) et
Biostatistiques et plus particulièrement Monsieur \textbf{Ducharme} pour
nous avoir permis de réaliser ce sujet.\\
Lors de ce projet, nous avons pu affiner notre travail en équipe et
notre autonomie, consolider nos acquis et ce rapport signe
l'aboutissement de notre première année de Master.\\
Nous remercions également nos proches qui nous ont soutenus dans
l'élaboration de notre projet et remercions notamment les participants à
notre expérience.\\
Remerciements spéciaux à nos relecteurs et correcteurs qui ont contribué
au bon déroulement du rapport.

\hypertarget{ruxe9sumuxe9}{%
\section{Résumé}\label{ruxe9sumuxe9}}

~ Dans différents cadres, la fraude est existante. Une façon répandue
pour commettre une fraude est de modifier des chiffres de données de la
manière dont le désire l'escroc et notamment en modifiant le premier
chiffre significatif. Ce que nous étudierons plus particulièrement ici.

Pour détecter ces fraudes, nous pouvons utiliser la loi de
Newcomb-Benford sur des échantillons de données.\\
L'objectif étant d'exposer l'émergence de la loi de Newcomb-Benford dans
des données réelles, d'étudier différents jeux de données comme ici la
fiscalité italienne et à l'aide de divers tests statistiques suspecter
ou non une fraude, par le biais de la modification du premier chiffre
significatif des nombres. Nous pourrons utiliser différents tests et
voir si ceux-ci vont plutôt dans le même sens ou si certains se
contredisent. Nous aborderons les tests dits classiques d'adéquation à
la loi de Newcomb-Benford, ainsi que les tests lisses mis en place par
Monsieur Ducharme et ses collaborateurs.

Pour répondre à nos différentes problématiques, nous allons effectuer
des expériences d'abord visuelles, en extrayant des données d'un
journal, d'un magazine ainsi que d'autres données réelles puis nous
appliquerons différents tests sur ces jeux de données à l'aide du
logiciel \texttt{R} et des packages \texttt{BenfordTests} et
\texttt{BENFORDSMOOTHTEST}. Nous utiliserons également ces packages sur
un jeu de données fiscales italiennes.

Les réponses récoltées dans le premier temps, nous montrerons que la loi
de Newcomb-Benford n'apparaît pas partout notamment sur les données
influencées par la pensée de l'homme, les données dites ``non
naturelles''. Nous observons également qu'une inspection visuelle n'est
pas suffisante pour suspecter ou non une fraude. Puis dans un second
temps, les tests réalisés nous permettront de voir qu'il est parfois
difficile de suspecter une fraude, au risque de se tromper.

\vspace{3.8cm}

\textbf{\underline{Mots-clés}} : Loi de Newcomb-Benford, \(1^{er}\)
chiffre significatif, Test d'hypothèses, Hypothèse nulle/alternative,
Risque d'erreur, Test d'adéquation, Test du khi-deux, Test lisse, Test
de Freedman, p-value.

\newpage
\tableofcontents

\newpage
\listoffigures

\newpage
\listoftables

\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

~ La fraude est une pratique répandue dans de nombreux domaines comme la
finance, le secteur social ou médical. Il peut être tentant pour un être
humain ou une société de tricher si cela peut impliquer pour lui une
position plus confortable dans la société, telle qu'une réduction de
charges, ou même un avantage sur un de ses concurrents. Il semblerait
donc logique que des personnes cherchent à déceler ces fraudes.

Les données transmises par un individu ou un organisme peuvent faire
l'objet de modifications, c'est de ce type de fraudes auquel nous nous
intéresserons ici, et plus particulièrement la modification du premier
chiffre significatif (le premier chiffre d'un nombre qui n'est pas un
zéro) de nombres pris dans un certain ensemble de données.

De telles modifications entraînent un changement de la répartition des
chiffres présents naturellement\footnote{Les données dites naturelles
  sont celles qui n'ont pas été influencées par la pensée de l'homme.}.
Si nous connaissons la répartition des chiffres présentés dans un
ensemble de données arbitraires, il est donc techniquement possible de
savoir si un nombre a été modifié ou non.

Il nous vient donc les questions suivantes : \emph{qu'elle est cette
répartition ? Est-il possible de la connaître et si oui, dans quels cas
?}

De manière intuitive, nous pourrions penser que les nombres sont
répartis de manière uniforme. Qu'en est-il vraiment ?

La première partie de notre projet consistera à \textbf{répondre à ces
questions}, nous nous appuierons sur les travaux de Simon Newcomb et
Frank Benford, qui ont théorisé la \textbf{loi de Newcomb-Benford}, plus
communément appelée loi de Benford. Cette loi nous dit que, dans une
liste de données dites naturelles, la probabilité d'avoir le chiffre
\(i\) comme premier chiffre significatif est de
\(log_{10}(1 + \frac{1}{i})\).

Par exemple, le chiffre \(1\) en tant que premier chiffre significatif
serait présent à hauteur de \(30\%\) alors que le \(9\) à seulement
\(4,6\%\).

Dans la suite \textbf{nous mettrons en œuvre une série
d'expérimentations} pour constater ou non la véracité de cette loi, pour
ce faire dans un premier temps, nous récolterons des nombres pris dans
des milieux censés satisfaire la loi de Newcomb-Benford et observerons
la répartition du premier chiffre significatif. Puis nous répliquerons
une version simplifiée de l'expérience de Hill (\(1988\)), qui consiste
à observer la répartition du premier chiffre significatif d'une liste de
nombre donnée au hasard par des êtres humains, en l'occurrence ses
élèves.

Cette expérience est à la base des méthodes de détection de fraudes et
s'explique par la loi de Newcomb-Benford. Si un fraudeur modifie un jeu
de données, ce jeu est ainsi influencé par la pensée humaine, et
celui-ci ne suit donc plus la loi de Newcomb-Benford. Pour détecter la
fraude, il faut alors comparer la distribution du premier chiffre
significatif d'un certain jeu de données, avec la distribution de la loi
de Newcomb-Benford. Cependant, ces comparaisons doivent se faire de
manière rigoureuse et scientifique. Pour cela, il existe des tests
statistiques d'adéquation à la loi de Newcomb-Benford, dont le plus
connu est le test du \(\chi^2\). Récemment, de nouveaux tests ont été
mis en place. Ce sont des tests lisses introduits par Ducharme et ses
collaborateurs en \(2020\).

Il nous vient donc les questions suivantes : \emph{ces tests sont-ils
fiables ? Existe-t-il un test significativement meilleur que les autres
? Vont-ils dans le même sens ? Et sinon que faire ?}

La réponse à ces questions constituera donc la deuxième partie de ce
projet, pour ce faire nous mettrons en œuvre différents tests sur des
jeux de données comme la fiscalité italienne.

\newpage

\hypertarget{genuxe8se-de-la-loi-de-newcomb-benford}{%
\section{Genèse de la loi de
Newcomb-Benford}\label{genuxe8se-de-la-loi-de-newcomb-benford}}

~ Il serait tentant de penser que les nombres sont répartis de manière
uniforme, cela viendrait du biais d'équiprobabilité\footnote{Défini en
  \(1985\) par Marie-Paule Lecoutre
  (\href{https://fr.wikipedia.org/wiki/Biais_d\%27\%C3\%A9quiprobabilit\%C3\%A9}{\emph{source}}).}.
Ce dernier consiste à ``penser qu'en l'absence d'information, tous les
cas ont la même probabilité de se produire et que le hasard implique
nécessairement l'uniformité''.

Néanmoins, cette hypothèse sera contredite une première fois par
l'astronome, mathématicien, économiste et statisticien canadien Simon
Newcomb. Ce dernier fournira en \(1881\) une première approche au
principe statistique, qui se fera injustement appeler \emph{Loi de
Benford}. Celui-ci remarquera que les premières pages des tables
logarithmiques sont plus utilisées que les pages suivantes (cf.~Figure
1). Il publiera sa découverte dans un article de l'\emph{``American
Journal of Mathematics''}.

\begin{center}\includegraphics[width=0.5\linewidth]{Images/table_loga1} \end{center}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth,height=\textheight]{Images/table_loga2.jpg}
\caption{Figure 1 : Table logarithmique recueillie par M. Ducharme
présentant des marques d'usure plus importantes sur les premières pages}
\end{figure}

Cette découverte mise de côté pendant plusieurs années, ce n'est qu'en
\(1938\) que l'ingénieur et physicien américain Frank Benford arrivera
au même résultat après avoir répertorié des dizaines de milliers de
données. Celui-ci pensera être le premier à l'initiative de cette loi,
et c'est pour cette raison que la \emph{loi de Newcomb-Benford} se fera
plus généralement appeler \emph{loi de Benford}.

Cette loi nous dit que, dans une liste de données arbitraires, la
probabilité d'avoir le chiffre \(i\) comme premier chiffre significatif
est de \(log_{10}(1 + \frac{1}{i})\).

\vspace{0.7cm}

\begin{table}


\begin{tabu} to \linewidth {>{}l>{\centering}X>{\centering}X>{\centering}X>{\centering}X>{\centering}X>{\centering}X>{\centering}X>{\centering}X>{\centering}X}
\toprule
\textbf{\cellcolor{gray!6}{PCS}} & \cellcolor{gray!6}{1} & \cellcolor{gray!6}{2} & \cellcolor{gray!6}{3} & \cellcolor{gray!6}{4} & \cellcolor{gray!6}{5} & \cellcolor{gray!6}{6} & \cellcolor{gray!6}{7} & \cellcolor{gray!6}{8} & \cellcolor{gray!6}{9}\\
\textbf{Benford} & 0.301 & 0.176 & 0.125 & 0.097 & 0.079 & 0.067 & 0.058 & 0.051 & 0.046\\
\bottomrule
\end{tabu}

\caption{Tableau 1 : Répartition du premier chiffre significatif selon la loi de Newcomb-Benford}
\end{table}

\vspace{0.7cm}

Nous retrouvons cette loi dans énormément de domaines comme les
mathématiques, l'environnement, la finance, la physique, etc, plus
précisément sur des données telles que la longueur des fleuves, la
population des villes dans un pays, des déclarations de revenus, etc.\\
Notons cependant qu'il existe des cas où les données ne suivent pas
cette loi, notamment des données dites non naturelles qui seraient
influencées par la pensée humaine (nombres premiers, nombres générés par
des humains, etc).

\newpage

\hypertarget{expuxe9rimentation-sur-diffuxe9rents-jeux-de-donnuxe9es}{%
\section{Expérimentation sur différents jeux de
données}\label{expuxe9rimentation-sur-diffuxe9rents-jeux-de-donnuxe9es}}

~ Après avoir pris connaissance de la \textbf{loi de Newcomb-Benford},
il serait intéressant de la mettre en pratique sur différents jeux de
données.

\hypertarget{la-suite-de-fibonacci}{%
\subsection{La suite de Fibonacci}\label{la-suite-de-fibonacci}}

~ Intéressons-nous dans un premier temps à la suite de Fibonacci.

Cette suite est une suite d'entiers dans laquelle chaque terme est la
somme des deux termes qui le précèdent. Sa formulation est la suivante :
\[F_{0} = 0, \, F_{1} = 1, \, \text{et} \, \forall \, n \ge 2, \, F_n = F_{n - 1} + F_{n - 2}.\]

Nous commençons par recueillir les \(1000\) premiers termes de la suite
de Fibonacci, pour extraire le premier chiffre significatif de chacun de
ces nombres.

Par la suite, nous calculons la répartition de chaque chiffre
significatif et obtenons l'histogramme suivant, où \(n\) ainsi que pour
l'ensemble des histogrammes suivants, représente le nombre de données de
l'échantillon :

\begin{figure}
\centering
\includegraphics{Images/histogramme_Fibonacci.png}
\caption{Figure 2 : Histrogramme de la répartition du 1er chiffre
significatif de la suite de Fibonacci en comparaison avec la loi de
Benford}
\end{figure}

Visuellement, il semblerait que la répartition des chiffres
significatifs des \(1000\) premiers nombres de la suite de Fibonacci
suive la \textbf{loi de Newcomb-Benford}.

\newpage

\hypertarget{nombres-extraits-dun-magazine-et-dun-journal}{%
\subsection{Nombres extraits d'un magazine et d'un
journal}\label{nombres-extraits-dun-magazine-et-dun-journal}}

~ Dans un second temps, nous relevons les prix présents dans un magazine
de mobilier de la marque \emph{AMPM}, ainsi que tous les nombres
répertoriés dans un journal \emph{Les ECHOS}. Nous récoltons environ
\(300\) nombres par magazine et, de la même façon qu'énoncé
précédemment, calculons la répartition des chiffres significatifs de ces
nombres.

\begin{figure}
\centering
\includegraphics{Images/histogramme_AMPM.png}
\caption{Figure 3 : Histrogramme de la répartition du 1er chiffre
significatif des prix du magazine AMPM en comparaison avec la loi de
Benford}
\end{figure}

La répartition des chiffres significatifs des prix du magazine
\emph{AMPM} parait fortement similaire à celle de la \textbf{loi de
Newcomb-Benford}. Nous constatons tout de même une légère différence
pour le chiffre \(3\).

Observons maintenant la répartition des données issues du journal
\emph{Les ECHOS}.

\begin{figure}
\centering
\includegraphics{Images/histogramme_journalLESECHOS.png}
\caption{Figure 4 : Histrogramme de la répartition du 1er chiffre
significatif des nombres du journal LES ECHOS en comparaison avec la loi
de Benford}
\end{figure}

Nous remarquons ici la même tendance décroissante. Cependant, les
proportions des chiffres significatifs entre les données du journal et
celles de la \textbf{loi de Newcomb-Benford} sont relativement
différentes.

\hypertarget{population-des-villes-de-france}{%
\subsection{Population des villes de
France}\label{population-des-villes-de-france}}

~ Dans ce paragraphe, nous nous intéressons à la population des villes
françaises. À l'aide des données de l'\emph{INSEE}, nous répertorions
environ \(35000\) premiers chiffres significatifs et regardons leur
répartition.

\begin{figure}
\centering
\includegraphics{Images/histogramme_populationfrancaise1.png}
\caption{Figure 5 : Histrogramme de la répartition du 1er chiffre
significatif de la population française en comparaison avec la loi de
Benford}
\end{figure}

Ici les répartitions sont fortement ressemblantes, c'est aussi le cas
pour de nombreuses données démographiques naturelles. Nous aurions pu
également analyser les codes postaux, la longueur des rivières ou encore
la distance des villes de France à Paris.

\newpage

\hypertarget{passage-journalier-de-vuxe9los-dans-lalluxe9e-beracasa-uxe0-montpellier}{%
\subsection{Passage journalier de vélos dans l'allée Beracasa à
Montpellier}\label{passage-journalier-de-vuxe9los-dans-lalluxe9e-beracasa-uxe0-montpellier}}

~ La ville de Montpellier étant en pleine transition écologique, elle
ouvre de plus en plus l'accès aux vélos sur ses routes. Pour en mesurer
l'impact, elle a mis en place des écocompteurs dans plusieurs rues. Les
données issues de ces compteurs sont en libre accès, nous nous sommes
donc intéressés au nombre de passages journaliers de vélos dans l'allée
Beracasa sur une année.

Nous obtenons la répartition suivante :

\begin{figure}
\centering
\includegraphics{Images/histogramme_velos.png}
\caption{Figure 6 : Histrogramme de la répartition du 1er chiffre
significatif du passage journalier de vélos en comparaison avec la loi
de Benford}
\end{figure}

Dans ce cas la proportion du chiffre \(1\) est de plus de \(50 \%\)
contre \(30 \%\) pour la \textbf{loi de Newcomb-Benford}. La différence
de répartition des chiffres \(2, 3, 4, 5\) est aussi notable, elle est
même environ \(2\) fois moins élevée.

Visuellement, nous pourrions penser que la répartition de ces données ne
suit pas la \textbf{loi de Newcomb-Benford}. Il est courant de ne pas
retrouver la loi de Newcomb-Benford dans des données brutes comme
celles-ci, on la retrouve empiriquement plus souvent dans des données
dites de \textbf{deuxième génération} comme des sommes ou des produits.
Ceci à été démontré par Jeff Boyle en \(1994\).

\hypertarget{nombres-guxe9nuxe9ruxe9s-par-les-humains}{%
\subsection{Nombres générés par les
humains}\label{nombres-guxe9nuxe9ruxe9s-par-les-humains}}

~ Dans ce paragraphe, nous tentons de reproduire à moindre échelle
l'expérience de Theodore Preston Hill en \(1988\). Dans le cadre de son
expérience le professeur Ted Hill demande à ses élèves (\(742\))
d'écrire un nombre de \(6\) chiffres au hasard sur un bout de papier, il
recense ensuite le premier chiffre significatif de chacun de ces nombres
dans le but de les comparer à la loi de Benford et à la répartition
uniforme.

Notre expérience partageant le même objectif que celle de Hill, est
basée sur un protocole légèrement différent. N'ayant pas une troupe
d'élèves à disposition nous avons recueilli un total de \(300\) nombres.
Ces \(300\) nombres ont été obtenus de plusieurs manières, via des
sondages sur internet ou sur les réseaux sociaux, en demandant
directement à des personnes rencontrées au hasard, notre famille ou nos
amis. Plus précisément, notre expérience a consisté à rechercher auprès
de ces personnes un nombre à \(2\) chiffres, soit un nombre compris
entre \(10\) et \(99\). Nous reviendrons plus loin sur l'importance que
peut avoir ce détail.

D'après le biais d'équiprobabilité cité plus haut, si les nombres
recensés pendant les expériences ont réellement été donnés de façon
aléatoire la répartition du premier chiffre significatif devrait être
comparable à une loi uniforme.

Comparons les répartitions obtenues durant les deux expériences :

\begin{figure}
\centering
\includegraphics{Images/comparaison.png}
\caption{Figure 7 : Comparaison des histrogrammes de la répartition du
1er chiffre significatif de l'expérience de Hill avec la loi de Benford
et la loi uniforme puis de notre expérience avec ces deux mêmes lois}
\end{figure}

À première vue, dans les deux expériences la répartition du premier
chiffre significatif ne semble pas suivre la loi de Newcomb-Benford (le
chiffre \(1\) n'apparaît clairement pas aussi souvent par exemple), elle
semble cependant plus proche de la loi uniforme sans tout de même y
correspondre parfaitement.

Plusieurs facteurs pourraient expliquer les différences entre la
distribution de la loi uniforme et la répartition du premier chiffre
significatif de notre expérience, celui qui revient souvent est qu'un
nombre donné au hasard par un humain est souvent influencé par son
expérience, même inconsciemment. Par exemple sa date d'anniversaire, un
évènement marquant ou son nombre préféré. Le fait d'avoir recueilli nos
nombres par internet a aussi pu influencer le choix des personnes
concernées. Un facteur psychologique est donc à prendre en considération
pour approfondir la conclusion. Notons également que lors de notre
expérience, la question posée stipulait de donner un nombre compris
entre \(10\) et \(99\), soit un nombre à \(2\) chiffres. Ainsi, il est
important de retenir que dès lorsqu'on demande un avec suffisamment de
chiffres, plus le premier chiffre aura tendance à suivre la loi de
Newcomb-Benford, mais la répartition des autres chiffres significatifs
(deuxième, troisième, etc.) ne sera apparentée à aucune loi. De même si
on demande un nombre avec peu de chiffres (choix d'un chiffre entre
\(1\) et \(9\) par exemple) la répartition aura plutôt tendance à être
uniforme. Ce phénomène a été exposé par A. Diekmann\footnote{Tiré de
  l'article \emph{Not the First Digit! Using Benford's Law To Detect
  Fraudulent Scientific Data} écrit par A. Diekmann en \(2007\)
  (\href{https://www.researchgate.net/publication/24083679_Not_the_First_Digit_Using_Benford\%27s_Law_to_Detect_Fraudulent_Scientif_ic_Data}{\emph{source}}).}
en \(2007\).

Après avoir observé ces quelques jeux de données, nous étions en mesure
de dire si ces données semblaient ou non suivre la loi de
Newcomb-Benford, le problème qui en découle est qu'une simple
observation n'est pas très fiable, difficile de prendre une décision sur
un constat visuel. En effet, se tromper dans l'interprétation peut
entraîner deux types d'erreurs, la première étant de faussement déceler
une fraude (ce que nous appellerons \textbf{le risque de première
espèce}) et la deuxième de laisser passer une fraude. Ces erreurs ont un
coût pour l'institut qui essaye de les réprimer, celui d'engager des
démarches de détections approfondies inutiles ou de ne pas percevoir les
taxes dues dans le cas de la fraude fiscale par exemple.

Le but est donc de minimiser le coût que peuvent engendrer les erreurs
susmentionnées, pour ce faire l'utilisation d'outils scientifiques est
de rigueur. Les outils que nous aborderons dans la suite sont les tests
d'adéquation, ces tests servent à vérifier si un ensemble de nombres
suit ou non une loi de probabilité donnée (dans notre cas, c'est la loi
de Newcomb-Benford).

\hypertarget{tests}{%
\section{Tests}\label{tests}}

\hypertarget{guxe9nuxe9ralituxe9s-sur-les-tests}{%
\subsection{Généralités sur les
tests}\label{guxe9nuxe9ralituxe9s-sur-les-tests}}

~ Un test d'hypothèses\footnote{\href{https://www.imo.universite-paris-saclay.fr/~pansu/web_ifips/Tests.pdf}{\emph{Source.}}}
(ou test statistique) est un procédé d'inférence statistique ayant pour
but de fournir une règle de décision permettant ainsi, à partir de
l'étude d'un ou plusieurs échantillons de données, d'indiquer si une
hypothèse statistique concernant une population doit être acceptée ou
rejetée.

Nous distinguons deux classes de tests :

\begin{itemize}
\tightlist
\item
  Les tests paramétriques sont l'étude de la moyenne, variance, ou de la
  fréquence des observations issues d'une distribution a priori
  paramétrée. Ils nécessitent un modèle à fortes contraintes (normalité
  des distributions ou approximation normale pour de grands
  échantillons). Ces hypothèses sont d'autant plus difficiles à vérifier
  que les effectifs étudiés sont plus réduits.\\
\item
  Les tests non paramétriques sont l'étude des rangs des observations
  issues d'une distribution non paramétrée, mais quelconque. Ce sont des
  tests dont le modèle ne précise pas les conditions que doivent remplir
  les paramètres de la population dont a été extrait l'échantillon. Il
  n'y a donc pas d'hypothèse de normalité au préalable.
\end{itemize}

Lorsque les conditions nécessaires sont valides, les tests paramétriques
sont plus puissants que les tests non paramétriques. Les tests non
paramétriques s'utilisent dès lors que les conditions d'application des
autres méthodes ne sont pas satisfaites, même après d'éventuelles
transformations de variables et peuvent être employés pour des
échantillons de taille très faible.

Comme nous l'avons précédemment énoncé, une inspection visuelle à elle
seule ne permet pas d'affirmer ou infirmer si un jeu de données suit la
loi de Newcomb-Benford. L'outil statistique permettant de le vérifier
est le test d'adéquation à la loi de Newcomb-Benford.\\
Les tests d'adéquation servent à tester si un échantillon est distribué
selon une loi de probabilité préalablement choisie. Ils permettent de
décider, avec un certain seuil d'erreur, si les écarts présentés par
l'échantillon par rapport aux valeurs théoriques sont dus au hasard, ou
si au contraire ils sont significatifs.

\hypertarget{hypothuxe8se-nulle-et-hypothuxe8se-alternative}{%
\subsection{Hypothèse nulle et hypothèse
alternative}\label{hypothuxe8se-nulle-et-hypothuxe8se-alternative}}

~ Un test statistique étudie deux hypothèses opposées concernant une
population : l'hypothèse nulle et l'hypothèse alternative.\\
L'hypothèse nulle, notée \(H_0\), est l'hypothèse que l'on souhaite
contrôler, elle repose sur le fait de dire qu'il n'existe pas de
différence entre les paramètres comparés ou que la différence observée
n'est pas significative et résulte des fluctuations d'échantillonnage.

À partir des échantillons de données, un test statistique permet de
déterminer si on peut rejeter l'hypothèse nulle. La \(p\)-valeur sert de
détermination. Si la \(p\)-valeur est inférieure au seuil de
signification (appelé \(\alpha\)), l'hypothèse nulle peut être rejetée.

L'hypothèse alternative, notée \(H_1\), affirme qu'un paramètre de la
population est plus petit, plus grand ou différent de la valeur
hypothétique dans l'hypothèse nulle. Elle peut être vue comme la
négation de \(H_0\) et est équivalente à dire que \(H_0\) est fausse. La
décision de rejeter \(H_0\) signifie que \(H_1\) est réalisée ou que
\(H_1\) est vraie.

On pense souvent à tort que les tests d'hypothèses statistiques visent à
choisir l'hypothèse la plus probable parmi \(H_0\) et \(H_1\). Néanmoins
l'hypothèse nulle est formulée dans le but d'être rejetée. Le seuil de
signification fixé est bas (généralement \(0.05\)), et lorsque
l'hypothèse nulle est rejetée cela prouve statistiquement que
l'hypothèse alternative est vraie. En revanche, si l'hypothèse nulle ne
peut être rejetée aucune preuve statistique ne montre que celle-ci est
vraie. La raison est qu'il n'y a pas de valeur fixée assurant que la
probabilité d'accepter à tort l'hypothèse nulle est petite.

Finalement, la décision d'accepter l'hypothèse nulle n'est pas
équivalente à dire que \(H_0\) est vraie et que \(H_1\) est fausse, mais
cela traduit uniquement l'idée selon laquelle il n'y a pas d'évidence
nette pour que \(H_0\) soit fausse. Un test conclu donc à rejeter ou à
ne pas rejeter l'hypothèse nulle mais jamais à l'accepter directement.
Notons cependant que dans certains cas rares, on peut se permettre
d'accepter \(H_0\), par exemple dans les cas où \(H_0\) et \(H_1\) sont
simples. Un test d'hypothèses est dit simple\footnote{J. Y. BAUDOT
  (\href{http://www.jybaudot.fr/Inferentielle/tests.html\#:~:text=Le\%20but\%20du\%20test\%20est,doit\%20rejeter\%20ou\%20non\%20H0.\&text=Ce\%20sont\%20l\%C3\%A0\%20des\%20tests,test\%20d\%27hypoth\%C3\%A8se\%20simple}{\emph{source}}).}
si on pose sous \(H_0\) le paramètre égal à une certaine valeur et sous
\(H_1\) celui-ci égal à une autre valeur.

Exemple de test entre deux hypothèses simples :\\
Tester \(H_0\) contre \(H_1\) avec
\(H_0 : \text{"} \theta = \theta_0 \text{"}\) et
\(H_1 : \text{"} \theta = \theta_1 \text{"}\).

Le test d'hypothèses simples s'oppose au test d'hypothèses composites.

Exemples de test entre deux hypothèses composites : Tester \(H_0\)
contre \(H_1\) avec \(H_0 : \text{"} \theta = \theta_0 \text{"}\) et
\(H_1 : \text{"} \theta \neq \theta_0 \text{"}\) (test bilatéral) et
tester \(H_0\) contre \(H_1\) avec
\(H_0 : \text{"} \theta = \theta_0 \text{"}\) et
\(H_1 : \text{"} \theta \geq \theta_0 \text{"}\) (test unilatéral)

Dans la suite de notre projet, nous nous intéresserons aux données
fiscales de \(20\) régions italiennes entre \(2007\) et \(2011\). Nous
réaliserons donc pour chacune de ces régions et chacune des années le
test d'hypothèses suivant : \(H_0\) : ``La répartition du premier
chiffre significatif suit la loi de Newcomb-Benford'' contre \(H_1\) :
``La répartition du premier chiffre significatif ne suit pas la loi de
Newcomb-Benford''.

\hypertarget{les-risques-derreurs}{%
\subsection{Les risques d'erreurs}\label{les-risques-derreurs}}

~ Notons alors qu'aucun test d'hypothèses n'est fiable à \(100 \%\), un
test étant basé sur des probabilités, il existe toujours un risque de
tirer une mauvaise conclusion. Lorsqu'un test d'hypothèses est effectué,
nous pouvons observer deux types d'erreurs, l'erreur de Type I dite
erreur de première espèce et l'erreur de Type II dite erreur de seconde
espèce. Les risques de ces deux erreurs sont inversement proportionnels
et sont déterminés par le seuil de signification (ou région critique) et
la puissance du test. Il est important de déterminer l'erreur qui
présente les conséquences les plus graves dans notre cas avant de
définir le risque que nous accepterons pour chaque erreur.

L'erreur de Type I consiste à rejeter l'hypothèse nulle alors que
celle-ci est vraie. La probabilité de commettre une erreur de première
espèce est représentée par \(\alpha\), qui désigne le seuil de
signification défini pour le test d'hypothèses. Ainsi, le seuil de
signification du test s'énonce en probabilité :

\[\alpha = \mathbb{P}(\text{rejeter} \, H_0 | H_0 \, \text{vraie}).\]

Un niveau \(\alpha\) de \(0.05\) indique que nous sommes disposé à avoir
\(5 \%\) de chances de rejeter l'hypothèse nulle à tort. Pour réduire ce
risque, il est possible d'utiliser une valeur \(\alpha\) plus faible.
Cependant, cela implique d'être moins à même de détecter une vraie
différence si celle-ci existe vraiment.\\
Dans notre contexte, l'erreur de Type I consiste à affirmer que les
données ne suivent pas la loi de Newcomb-Benford alors que c'est le cas,
soit faussement identifier une fraude. Il est important de noter que
faussement identifier un fraude peut s'avérer très coûteux.

L'erreur de Type II repose sur le fait de ne pas rejeter l'hypothèse
nulle alors que celle-ci est fausse. La probabilité de commettre une
erreur de seconde espèce est notée \(\beta\), et dépend de la puissance
du test. Il est possible de réduire le risque de deuxième espèce en
faisant en sorte que le test soit suffisamment puissant. Pour cela, il
est nécessaire que l'effectif d'échantillon soit suffisamment grand pour
permettre la détection d'une différence réelle.\\
La probabilité de rejeter l'hypothèse nulle à tort vaut \(1 - \beta\),
il s'agit de la puissance du test. Finalement, la puissance d'un test
est donnée par :\\
\[1 - \beta = \mathbb{P}(\text{rejeter} \, H_0 | H_1 \, \text{vraie}).\]

\begin{table}

\begin{table}[H]
\centering
\begin{tabular}{>{\centering\arraybackslash}p{12em}|>{\centering\arraybackslash}p{12em}|>{\centering\arraybackslash}p{12em}}
\hline
\multicolumn{1}{c|}{\textbf{Décision d'après l'échantillon}} & \multicolumn{2}{c}{\textbf{Réalité sur la population}} \\
\cline{1-1} \cline{2-3}
 & $H_0$ est vraie & $H_0$ est fausse\\
\hline
Ne pas rejeter $H_0$ & Décision juste (probabilité = 1 - $\alpha$) & Erreur de seconde espèce : acceptation de $H_0$ alors que celle-ci est fausse (probabilité = $\beta$)\\
\hline
Rejeter $H_0$ & Erreur de première espèce : rejet de $H_0$ alors que celle-ci est vrai (probabilité = $\alpha$) & Décision juste (probabilité = 1 - $\beta$)\\
\hline
\end{tabular}
\end{table}

\caption{Tableau 2 : Règle de décision et risques d'erreurs}
\end{table}

\vspace{0.2cm}

Au sujet de la loi de Newcomb-Benford, notons que le test d'adéquation
le plus populaire est le test du khi-deux de Pearson dont la puissance,
associée au risque d'erreur de Type II est relativement faible. C'est
pourquoi d'autres tests ont été mis en place récemment. L'ensemble de
ces tests seront développés par la suite.\\
G. Ducharme, S. Kaci et C. Vovor-Dassu\footnote{Tests d'adéquations
  lisses pour la loi de Newcomb-Benford écrit en \(2020\)
  (\href{http://openscience.fr/IMG/pdf/iste_mas20v3n1_1.pdf}{\emph{source}}).}
ont introduits de nouveaux tests d'adéquation pour cette loi, basés sur
le principe des tests lisses. Ils ont également comparé ces tests aux
meilleurs tests existants et ont montré qu'ils seraient globalement plus
performants. Notons aussi que la qualité d'un test dépend de sa
puissance, plus forte elle est meilleur est le test. Cependant,
différents tests peuvent conduire à des avantages différents. Par
exemple, certains tests détecteront plus que d'autres la différence
significative du premier chiffre significatif, quant à d'autres, ce sera
un autre chiffre significatif.

\newpage

\hypertarget{test-du-khi-deux}{%
\subsection{Test du Khi-Deux}\label{test-du-khi-deux}}

~ Les tests du \(\chi^2\) sont des tests d'hypothèses statistiques non
paramétriques\footnote{Cette partie a été fortement inspirée du site
  \emph{Bibmath} (cf Bibliographie).}. Ceux-ci permettent de comparer la
distribution observée dans un échantillon statistique avec une
distribution théorique (\emph{test d'ajustement}), à tester si deux
caractères d'une population sont indépendants (\emph{test
d'indépendance}) et à tester si des échantillons sont issus d'une même
population (\emph{test d'homogénéité}). Le test lit l'écart critique
dans la table de la loi du khi-deux.

Le déroulement du test se procède en \(5\) étapes :\\
1) On calcule les effectifs théoriques (\emph{\(n_{pj}\)}).\\
2) On calcule la valeur observée de la variable de test :\\
\[\chi^{2}=\sum_{j=1}^{k} \frac{\left(n_{j}-n _{p_{j}}\right)^{2}}{n_{ p_{j}}}.\]\\
3) On cherche la valeur critique \(\chi^{2}_a\) dans la table de la loi
du \(\chi^2\) à \(k - 1\) degrés de liberté.\\
4) Si \(\chi^{2}_a < \chi^2\), on ne rejette pas l'hypothèse \(H_0\)
(``la distribution observée est conforme à la distribution théorique''
avec un risque d'erreur \(\alpha\)), sinon on la rejette.\\
5) Il faut vérifier que \(n_{pj} \geq 5\) pour tout \(j\).

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth,height=\textheight]{Images/Chi-square.png}
\caption{Figure 8 : Densité de la loi du Khi-Deux en fonction du nombre
de degrés de liberté}
\end{figure}

La loi du \(\chi^2\) à \(n\) degrés de liberté si elle est absolument
continue, admet pour densité :

\vspace{0.5cm}

\fbox{ \begin{minipage}{18.2cm}
$$f(x)=\left\{\begin{array}{cl}\frac{1}{2^{n / 2} \Gamma(n / 2)} e^{-x / 2} x^{\frac{n}{2}-1} & \text { si } x>0, \\ 0 & \text { sinon, }\end{array}\right.$$

où $X$ admet alors pour espérance et variance $E(X) = n$ et $V(X) = 2n$.  
\end{minipage}}

\vspace{0.5cm}

\hypertarget{test-de-freedman-watson}{%
\subsection{Test de Freedman-Watson}\label{test-de-freedman-watson}}

~ Le test de Freedman peut être adapté à des données discrètes, il
permet de comparer la distribution du premier chiffre significatif d'un
échantillon de données avec la distribution de la loi de Newcomb-Benford
et ainsi affirmer si la répartition du premier chiffre significatif cet
échantillon est bien conforme à la loi de Newcomb-Benford.

Spécifiquement, la statistique de test (dans le cas \(k = 1\)) est
donnée par :

\vspace{0.5cm}

\fbox{ \begin{minipage}{18.2cm}
$$U^{2}=\frac{n}{9} \cdot\left[\sum_{i=1}^{8}\left(\sum_{j=1}^{i}\left(f_{j}^{o}-f_{j}^{e}\right)\right)^{2}-\frac{1}{9} \cdot\left(\sum_{i=1}^{8} \sum_{j=1}^{i}\left(f_{i}^{o}-f_{i}^{e}\right)\right)^{2}\right],$$  

avec $f_{i}^{o}$ la fréquence observée du chiffre $i$ et $f_{i}^{e}$ la fréquence attendue du chiffre $i$.  
\end{minipage}}

\vspace{0.5cm}

Notons que de plus grands écarts entre les fréquences conduisent à un
plus grand \(U^2\), ce qui rend le rejet plus probable. Ce test est
reconnu comme plus performant que d'autres tests et a même été
recommandé par la statisticienne M. Lesperance ainsi que ses
collaborateurs (\(2016\)), puis également par Joenssen (\(2014\)).

\newpage

\hypertarget{tests-lisses-pour-la-loi-de-newcomb-benford}{%
\subsection{Tests lisses pour la Loi de
Newcomb-Benford}\label{tests-lisses-pour-la-loi-de-newcomb-benford}}

~ La famille des tests lisses introduite par Neyman s'applique à des
données autant discrètes que continues. Celle-ci est spécifique à la loi
de probabilité sous \(H_0\).

Il existe deux théorèmes essentiels tirés de l'article ``\emph{Smooth
test of goodness-of-fit for directional and axial data}'' écrit par
BOULERICE B., DUCHARME G.R. en 1997 qui permettent de construire une
famille de tests lisses pour l'hypothèse nulle \(H_{0} : X \sim f(.)\).
Ici \(f(.)\) est la densité de la loi de Newcomb-Benford.

Le premier théorème nous dit:

\vspace{0.5cm}

\fbox{ \begin{minipage}{18.2cm} \underline{Théorème 1} : Soit $X_{1}, \dots, X_{n}$ des copies indépendantes d'une variable aléatoire $X$ de densité $f(\cdot)$ par rapport à une mesure dominante $\nu .$ Soit $\left\{h_{0}(\cdot) \equiv 1, h_{k}(\cdot), k=1,2, \dots\right\}$ une suite de fonctions orthonormales par rapport à $f(\cdot) ;$ plus précisément, $\displaystyle \int h_{k}(x) h_{k^{\prime}}(x) f(x) d \nu(x)=\delta_{k k^{\prime}}$, la fonction delta de Kronecker. Soit $U_{k}=n^{-1 / 2} \displaystyle \sum_{i=1}^{n} h_{k}\left(X_{i}\right)$ et pour un entier $K \geq 1$, soit $T_{K} = \displaystyle \sum_{k=1}^{K} U_{k}^{2}$. \par
Alors sous $H_{0}, T_{K} \stackrel{L}{\longrightarrow} \chi_{K}^{2}$, la loi khi-deux à $K$ degrés de liberté, et un test de niveau asymptotique $\alpha$ rejette $H_{0}$ si la valeur observée de $T_{K}$ dépasse $x_{K, 1-\alpha}^{2}$, le quantile d'ordre $1-\alpha$ de cette loi $\chi_{K}^{2}$.  \end{minipage} }

\vspace{0.5cm}

Nous avons donc nos statistiques de test \(T_K\). Exprimons maintenant
les \(h_k\).\\
Dans la suite l'indice \(0\) dénote un opérateur probabiliste calculé
sous \(H_0\) : \(X\) suit \(f(.)\).

Nous avons également le théorème qui suit :

\vspace{0.5cm}

\fbox{ \begin{minipage}{18.2cm} \underline{Théorème 2} : Soit $\mu_{k}=\mathbb{E}_{0}\left(X^{k}\right), k \geq 0 .$ Soit aussi la matrice $\mathbf{M}_{k}=\left[\mu_{i+i^{\prime}}\right]_{i, i^{\prime}=0, \dots, k-1}$, le vecteur
$\boldsymbol{\mu}_{k}=\left(\mu_{k}, \mu_{k+1}, \dots \mu_{2 k-1}\right)^{T}$ et la constante $c_{k}=\mu_{2 k}-\boldsymbol{\mu}_{k}^{T} \mathbf{M}_{k}^{-1} \boldsymbol{\mu}_{k}$. Alors les polynômes
$$
h_{k}(x)=c_{k}^{-1 / 2}\left(x^{k}-\left(1, x, x^{2}, \dots, x^{k-1}\right) \mathbf{M}_{k}^{-1} \boldsymbol{\mu}_{k}\right)
$$
satisfont la condition du Théorème 1.
\end{minipage} }

\vspace{0.5cm}

D'après le Théorème 2, et Ducharme \& Collab. nous avons pour
\(0<k\leq5\) les \(h_k\) suivants :

\[
\begin{array}{l}
h_{1}(x)=-1.3979+0.4063 x, \\
h_{2}(x)=2.2836-1.6128 x+0.18247 x^{2}, \\
h_{3}(x)=4.0815+4.5719 x-1.2053 x^{2}+0.0862 x^{3}, \\
h_{4}(x)=8.0795-12.0946 x+5.1951 x^{2}-0.8249 x^{3}+0.0431 x^{4}, \\
h_{5}(x)=-18.1064+33.1385 x-19.7207 x^{2}+5.0168 x^{3}-0.5665 x^{4}+0.0233 x^{5}.
\end{array}
\]

Nous définissons :

\vspace{0.5cm}

\fbox{ \begin{minipage}{18.2cm}
$$\hat{K}=\underset{1 \leq k \leq K_{\max }}{\arg \max }\left\{T_{k}-k \log (n)\right\}, $$
et la statistique de test $T_{\hat{K}} \stackrel{L}{\longrightarrow} \chi_{1}^{2}$ sous $H_{0}$.
\end{minipage} }

\vspace{0.5cm}

Dans la suite, nous appliquerons les tests \(T_{\hat{K}}\) et \(T_2\)
avec \(K_{max} = 5\) qui d'après Ducharme \& Collab. sont les plus
performants.

\newpage

\hypertarget{application-des-tests}{%
\section{Application des tests}\label{application-des-tests}}

~ Nous traitons sur nos différents jeux de données et sur la fiscalité
italienne de \(20\) régions, ces données nous serviront à appliquer
différents tests (classique ou lisse). Chacun des tests teste
l'hypothèse nulle ``la répartition du premier chiffre significatif suit
la loi de Newcomb-Benford'' contre l'hypothèse alternative ``la
répartition du premier chiffre significatif ne suit pas la loi de
Newcomb-Benford''. L'objectif ici est d'approuver nos résultats si les
données étudiées suivent ou non la loi de Newcomb-Benford et de chercher
à savoir si certaines régions d'Italie modifient ou non leurs chiffres,
mais aussi de comparer les résultats de nos différents tests.

Nous retenons le test du khi-deux qui est le plus connu et utilisé, il
semblerait cependant qu'il fasse partie des moins performants (Ducharme
\& Collab. \(2020\)), le test de Freedman-Watson explicité plus haut.
Pour ce qui est des tests lisses nous appliquerons les tests
\(T_{\hat{K}}\) et \(T_2\) comme susmentionné.

\hypertarget{application-sur-nos-jeux-de-donnuxe9es}{%
\subsection{Application sur nos jeux de
données}\label{application-sur-nos-jeux-de-donnuxe9es}}

~ Dans cette partie nous cherchons à confirmer ou non nos hypothèses
formulées à la vue des graphiques. Nous utilisons les tests cités plus
haut. Les données se présentent comme ci-après, chaque ligne correspond
à une de nos expériences, les \(9\) premières colonnes (sans compter la
première qui correspond à l'expérience) représente la répartition du
premier chiffre significatif. Les \(4\) dernières colonnes quant à elles
sont les \(p\)-values des différents tests. Une case est rouge si
l'hypothèse nulle est rejetée au seuil de \(5 \%\) d'erreur.

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}l|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{Fibonacci} & 0.301 & 0.177 & 0.125 & 0.095 & 0.080 & 0.067 & 0.056 & 0.053 & 0.045 & \cellcolor{white}{\textbf{1.000}} & \cellcolor{white}{\textbf{1.000}} & \cellcolor{white}{\textbf{0.998}} & \cellcolor{white}{\textbf{0.961}}\\
\hline
\textbf{AMPM} & 0.293 & 0.180 & 0.107 & 0.100 & 0.087 & 0.070 & 0.067 & 0.053 & 0.043 & \cellcolor{white}{\textbf{0.990}} & \cellcolor{white}{\textbf{0.939}} & \cellcolor{white}{\textbf{0.872}} & \cellcolor{white}{\textbf{0.623}}\\
\hline
\textbf{Les echos} & 0.235 & 0.161 & 0.142 & 0.116 & 0.110 & 0.077 & 0.074 & 0.055 & 0.029 & \cellcolor{white}{\textbf{0.096}} & \cellcolor{red}{\textbf{0.002}} & \cellcolor{red}{\textbf{0.002}} & \cellcolor{red}{\textbf{0.000}}\\
\hline
\textbf{Population} & 0.274 & 0.188 & 0.133 & 0.095 & 0.084 & 0.072 & 0.059 & 0.052 & 0.044 & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}}\\
\hline
\textbf{Velos} & 0.525 & 0.098 & 0.056 & 0.053 & 0.042 & 0.056 & 0.056 & 0.071 & 0.048 & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}}\\
\hline
\textbf{Humains} & 0.135 & 0.140 & 0.113 & 0.100 & 0.123 & 0.107 & 0.097 & 0.077 & 0.087 & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}} & \cellcolor{red}{\textbf{0.000}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

Les tests sont unanimes, la suite de Fibonacci et les données relevées
sur le magazine AMPM suivent la loi de Newcomb-Benford, du moins on ne
rejette pas cette hypothèse, ce résultat est en accord avec nos
suppositions.

Regardons maintenant les tests appliqués au jeu de données tiré du
magazine \emph{les échos}, nous avions remarqué une tendance
décroissante similaire à celle de la répartition de la loi de
Newcomb-Benford, avec cependant des valeurs relativement différentes.
Les deux tests lisses ainsi que le test de Freedman donnent une
\(p\)-value proche de zéro qui nous mène à un fort rejet de l'hypothèse
nulle (avec un risque d'erreur presque nul), contrairement au test du
\(\chi^2\) (ici une \(p\)-value d'environ \(0,1\) nous indique que si
nous rejetons l'hypothèse nulle nous avons environ \(10 \%\) de chance
de nous tromper). On remarque ici que ce dernier est possiblement moins
puissant que les autres.

Pour terminer, tous les tests mènent à un rejet de l'hypothèse nulle
``le jeu de donnée suit la loi de N-B'' pour les jeux de données sur les
populations des villes de France, le passage journalier de vélos et les
nombres générés par les humains. Pour les deux derniers pas de surprise,
cependant le rejet de l'hypothèse nulle pour le jeu de données sur les
populations des villes de France nous paraît étonnant, l'inspection
visuelle nous donnait l'impression que la répartition du PCS collait à
celle de la loi de Newcomb-Benford, mais le nombre important de données
à fortement amplifié les différences.

Les différents tests nous ont permis ici de déceler des différences avec
la loi de N-B qui nous ont échappés à l'oeil nu, mais aussi de nous
rendre compte de la différence d'efficacité entre les tests.

\hypertarget{application-uxe0-des-donnuxe9es-fiscales-italiennes}{%
\subsection{Application à des données fiscales
italiennes}\label{application-uxe0-des-donnuxe9es-fiscales-italiennes}}

~ Les données utilisées dans cette partie sont tirées d'un article (voir
bibliographie) traitant sur la fraude de données fiscales en Italie. Les
données se présentent comme ci-après, chaque ligne correspond à une
année, les \(9\) premières colonnes (sans compter la première qui
correspond à l'année) représente la répartition du premier chiffre
significatif. Les \(4\) dernières colonnes quant à elles sont les
\(p\)-values des différents tests que nous avons cités plus haut. Une
case est rouge si l'hypothèse nulle est rejetée au seuil de \(5 \%\)
d'erreur.

Les \(12\) premiers tableaux ci-dessus ne montrent pas de suspections de
fraude dans leurs données avec les divers tests sélectionnés.

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.292 & 0.187 & 0.105 & 0.085 & 0.089 & 0.056 & 0.075 & 0.052 & 0.059 & \cellcolor{white}{\textbf{0.716}} & \cellcolor{white}{\textbf{0.135}} & \cellcolor{white}{\textbf{0.396}} & \cellcolor{white}{\textbf{0.332}}\\
\hline
\textbf{2008} & 0.295 & 0.170 & 0.111 & 0.089 & 0.098 & 0.059 & 0.062 & 0.056 & 0.059 & \cellcolor{white}{\textbf{0.870}} & \cellcolor{white}{\textbf{0.220}} & \cellcolor{white}{\textbf{0.465}} & \cellcolor{white}{\textbf{0.309}}\\
\hline
\textbf{2009} & 0.289 & 0.164 & 0.111 & 0.102 & 0.079 & 0.062 & 0.066 & 0.056 & 0.072 & \cellcolor{white}{\textbf{0.637}} & \cellcolor{white}{\textbf{0.146}} & \cellcolor{white}{\textbf{0.103}} & \cellcolor{white}{\textbf{0.091}}\\
\hline
\textbf{2010} & 0.298 & 0.154 & 0.121 & 0.092 & 0.085 & 0.069 & 0.066 & 0.052 & 0.062 & \cellcolor{white}{\textbf{0.918}} & \cellcolor{white}{\textbf{0.115}} & \cellcolor{white}{\textbf{0.331}} & \cellcolor{white}{\textbf{0.211}}\\
\hline
\textbf{2011} & 0.318 & 0.144 & 0.115 & 0.095 & 0.079 & 0.062 & 0.079 & 0.059 & 0.049 & \cellcolor{white}{\textbf{0.746}} & \cellcolor{white}{\textbf{0.248}} & \cellcolor{white}{\textbf{0.443}} & \cellcolor{white}{\textbf{0.380}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 3 : Tests sur la région d'Abruzzo}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.290 & 0.160 & 0.130 & 0.061 & 0.122 & 0.076 & 0.061 & 0.023 & 0.076 & \cellcolor{white}{\textbf{0.267}} & \cellcolor{white}{\textbf{0.289}} & \cellcolor{white}{\textbf{0.708}} & \cellcolor{white}{\textbf{0.428}}\\
\hline
\textbf{2008} & 0.282 & 0.168 & 0.107 & 0.107 & 0.084 & 0.092 & 0.031 & 0.061 & 0.069 & \cellcolor{white}{\textbf{0.718}} & \cellcolor{white}{\textbf{0.633}} & \cellcolor{white}{\textbf{0.558}} & \cellcolor{white}{\textbf{0.314}}\\
\hline
\textbf{2009} & 0.290 & 0.160 & 0.122 & 0.099 & 0.061 & 0.099 & 0.053 & 0.053 & 0.061 & \cellcolor{white}{\textbf{0.894}} & \cellcolor{white}{\textbf{0.225}} & \cellcolor{white}{\textbf{0.647}} & \cellcolor{white}{\textbf{0.388}}\\
\hline
\textbf{2010} & 0.290 & 0.168 & 0.115 & 0.092 & 0.076 & 0.122 & 0.023 & 0.053 & 0.061 & \cellcolor{white}{\textbf{0.287}} & \cellcolor{white}{\textbf{0.745}} & \cellcolor{white}{\textbf{0.785}} & \cellcolor{white}{\textbf{0.493}}\\
\hline
\textbf{2011} & 0.305 & 0.160 & 0.099 & 0.115 & 0.053 & 0.122 & 0.046 & 0.046 & 0.053 & \cellcolor{white}{\textbf{0.348}} & \cellcolor{white}{\textbf{0.505}} & \cellcolor{white}{\textbf{0.874}} & \cellcolor{white}{\textbf{0.611}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 4 : Tests sur la région de Basilicata}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.298 & 0.152 & 0.132 & 0.098 & 0.073 & 0.073 & 0.068 & 0.046 & 0.059 & \cellcolor{white}{\textbf{0.816}} & \cellcolor{white}{\textbf{0.328}} & \cellcolor{white}{\textbf{0.481}} & \cellcolor{white}{\textbf{0.270}}\\
\hline
\textbf{2008} & 0.301 & 0.164 & 0.127 & 0.093 & 0.073 & 0.068 & 0.073 & 0.042 & 0.059 & \cellcolor{white}{\textbf{0.808}} & \cellcolor{white}{\textbf{0.258}} & \cellcolor{white}{\textbf{0.599}} & \cellcolor{white}{\textbf{0.446}}\\
\hline
\textbf{2009} & 0.298 & 0.164 & 0.120 & 0.100 & 0.064 & 0.076 & 0.071 & 0.049 & 0.059 & \cellcolor{white}{\textbf{0.764}} & \cellcolor{white}{\textbf{0.481}} & \cellcolor{white}{\textbf{0.378}} & \cellcolor{white}{\textbf{0.270}}\\
\hline
\textbf{2010} & 0.308 & 0.166 & 0.115 & 0.103 & 0.061 & 0.081 & 0.073 & 0.051 & 0.042 & \cellcolor{white}{\textbf{0.712}} & \cellcolor{white}{\textbf{0.606}} & \cellcolor{white}{\textbf{0.921}} & \cellcolor{white}{\textbf{0.719}}\\
\hline
\textbf{2011} & 0.301 & 0.166 & 0.117 & 0.095 & 0.073 & 0.086 & 0.064 & 0.054 & 0.044 & \cellcolor{white}{\textbf{0.933}} & \cellcolor{white}{\textbf{0.379}} & \cellcolor{white}{\textbf{0.814}} & \cellcolor{white}{\textbf{0.521}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 5 : Tests sur la région de Calabria}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.304 & 0.193 & 0.119 & 0.095 & 0.061 & 0.058 & 0.053 & 0.056 & 0.061 & \cellcolor{white}{\textbf{0.760}} & \cellcolor{white}{\textbf{0.076}} & \cellcolor{white}{\textbf{0.302}} & \cellcolor{white}{\textbf{0.974}}\\
\hline
\textbf{2008} & 0.310 & 0.188 & 0.127 & 0.093 & 0.069 & 0.050 & 0.066 & 0.042 & 0.056 & \cellcolor{white}{\textbf{0.823}} & \cellcolor{white}{\textbf{0.177}} & \cellcolor{white}{\textbf{0.566}} & \cellcolor{white}{\textbf{0.654}}\\
\hline
\textbf{2009} & 0.315 & 0.193 & 0.116 & 0.087 & 0.082 & 0.048 & 0.061 & 0.040 & 0.058 & \cellcolor{white}{\textbf{0.659}} & \cellcolor{white}{\textbf{0.302}} & \cellcolor{white}{\textbf{0.421}} & \cellcolor{white}{\textbf{0.539}}\\
\hline
\textbf{2010} & 0.320 & 0.190 & 0.119 & 0.093 & 0.077 & 0.053 & 0.056 & 0.034 & 0.058 & \cellcolor{white}{\textbf{0.690}} & \cellcolor{white}{\textbf{0.338}} & \cellcolor{white}{\textbf{0.370}} & \cellcolor{white}{\textbf{0.332}}\\
\hline
\textbf{2011} & 0.312 & 0.198 & 0.127 & 0.079 & 0.077 & 0.061 & 0.045 & 0.048 & 0.053 & \cellcolor{white}{\textbf{0.829}} & \cellcolor{white}{\textbf{0.138}} & \cellcolor{white}{\textbf{0.436}} & \cellcolor{white}{\textbf{0.375}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 6 : Tests sur la région de la Lazio}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.279 & 0.210 & 0.142 & 0.078 & 0.055 & 0.059 & 0.068 & 0.064 & 0.046 & \cellcolor{white}{\textbf{0.639}} & \cellcolor{white}{\textbf{0.083}} & \cellcolor{white}{\textbf{0.889}} & \cellcolor{white}{\textbf{0.878}}\\
\hline
\textbf{2008} & 0.289 & 0.220 & 0.138 & 0.078 & 0.046 & 0.073 & 0.055 & 0.064 & 0.037 & \cellcolor{white}{\textbf{0.439}} & \cellcolor{white}{\textbf{0.347}} & \cellcolor{white}{\textbf{0.840}} & \cellcolor{white}{\textbf{0.602}}\\
\hline
\textbf{2009} & 0.280 & 0.220 & 0.142 & 0.078 & 0.041 & 0.069 & 0.064 & 0.064 & 0.041 & \cellcolor{white}{\textbf{0.343}} & \cellcolor{white}{\textbf{0.097}} & \cellcolor{white}{\textbf{0.911}} & \cellcolor{white}{\textbf{0.870}}\\
\hline
\textbf{2010} & 0.303 & 0.206 & 0.142 & 0.073 & 0.050 & 0.073 & 0.060 & 0.060 & 0.032 & \cellcolor{white}{\textbf{0.590}} & \cellcolor{white}{\textbf{0.091}} & \cellcolor{white}{\textbf{0.731}} & \cellcolor{white}{\textbf{0.441}}\\
\hline
\textbf{2011} & 0.284 & 0.211 & 0.151 & 0.069 & 0.055 & 0.073 & 0.041 & 0.073 & 0.041 & \cellcolor{white}{\textbf{0.287}} & \cellcolor{white}{\textbf{0.182}} & \cellcolor{white}{\textbf{0.897}} & \cellcolor{white}{\textbf{0.805}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 7 : Tests sur la région de Friuli-Venezia-Giulia}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.298 & 0.168 & 0.118 & 0.092 & 0.087 & 0.074 & 0.064 & 0.050 & 0.048 & \cellcolor{white}{\textbf{0.725}} & \cellcolor{white}{\textbf{0.449}} & \cellcolor{white}{\textbf{0.479}} & \cellcolor{white}{\textbf{0.225}}\\
\hline
\textbf{2008} & 0.297 & 0.175 & 0.115 & 0.089 & 0.085 & 0.073 & 0.070 & 0.045 & 0.051 & \cellcolor{white}{\textbf{0.287}} & \cellcolor{white}{\textbf{0.163}} & \cellcolor{white}{\textbf{0.403}} & \cellcolor{white}{\textbf{0.197}}\\
\hline
\textbf{2009} & 0.299 & 0.176 & 0.114 & 0.093 & 0.085 & 0.072 & 0.070 & 0.048 & 0.043 & \cellcolor{white}{\textbf{0.500}} & \cellcolor{white}{\textbf{0.395}} & \cellcolor{white}{\textbf{0.759}} & \cellcolor{white}{\textbf{0.526}}\\
\hline
\textbf{2010} & 0.296 & 0.172 & 0.119 & 0.096 & 0.082 & 0.071 & 0.069 & 0.054 & 0.043 & \cellcolor{white}{\textbf{0.792}} & \cellcolor{white}{\textbf{0.456}} & \cellcolor{white}{\textbf{0.490}} & \cellcolor{white}{\textbf{0.258}}\\
\hline
\textbf{2011} & 0.300 & 0.172 & 0.117 & 0.097 & 0.078 & 0.074 & 0.067 & 0.051 & 0.043 & \cellcolor{white}{\textbf{0.775}} & \cellcolor{white}{\textbf{0.258}} & \cellcolor{white}{\textbf{0.783}} & \cellcolor{white}{\textbf{0.507}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 8 : Tests sur la région de Lombardia}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.304 & 0.185 & 0.119 & 0.091 & 0.088 & 0.061 & 0.064 & 0.052 & 0.036 & \cellcolor{white}{\textbf{0.616}} & \cellcolor{white}{\textbf{0.430}} & \cellcolor{white}{\textbf{0.626}} & \cellcolor{white}{\textbf{0.459}}\\
\hline
\textbf{2008} & 0.300 & 0.186 & 0.112 & 0.096 & 0.085 & 0.065 & 0.065 & 0.044 & 0.047 & \cellcolor{white}{\textbf{0.739}} & \cellcolor{white}{\textbf{0.418}} & \cellcolor{white}{\textbf{0.999}} & \cellcolor{white}{\textbf{0.963}}\\
\hline
\textbf{2009} & 0.303 & 0.180 & 0.110 & 0.095 & 0.090 & 0.061 & 0.061 & 0.053 & 0.046 & \cellcolor{white}{\textbf{0.766}} & \cellcolor{white}{\textbf{0.373}} & \cellcolor{white}{\textbf{0.925}} & \cellcolor{white}{\textbf{0.787}}\\
\hline
\textbf{2010} & 0.304 & 0.185 & 0.111 & 0.094 & 0.086 & 0.055 & 0.055 & 0.054 & 0.041 & \cellcolor{white}{\textbf{0.826}} & \cellcolor{white}{\textbf{0.261}} & \cellcolor{white}{\textbf{0.626}} & \cellcolor{white}{\textbf{0.360}}\\
\hline
\textbf{2011} & 0.299 & 0.186 & 0.114 & 0.095 & 0.076 & 0.056 & 0.056 & 0.051 & 0.042 & \cellcolor{white}{\textbf{0.680}} & \cellcolor{white}{\textbf{0.311}} & \cellcolor{white}{\textbf{0.621}} & \cellcolor{white}{\textbf{0.384}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 9 : Tests sur la région de Piemonte}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.306 & 0.194 & 0.116 & 0.089 & 0.089 & 0.043 & 0.054 & 0.047 & 0.062 & \cellcolor{white}{\textbf{0.751}} & \cellcolor{white}{\textbf{0.305}} & \cellcolor{white}{\textbf{0.589}} & \cellcolor{white}{\textbf{0.848}}\\
\hline
\textbf{2008} & 0.295 & 0.213 & 0.101 & 0.101 & 0.074 & 0.078 & 0.039 & 0.047 & 0.054 & \cellcolor{white}{\textbf{0.648}} & \cellcolor{white}{\textbf{0.907}} & \cellcolor{white}{\textbf{0.903}} & \cellcolor{white}{\textbf{0.750}}\\
\hline
\textbf{2009} & 0.291 & 0.217 & 0.101 & 0.097 & 0.074 & 0.078 & 0.035 & 0.062 & 0.047 & \cellcolor{white}{\textbf{0.509}} & \cellcolor{white}{\textbf{0.623}} & \cellcolor{white}{\textbf{0.939}} & \cellcolor{white}{\textbf{0.828}}\\
\hline
\textbf{2010} & 0.302 & 0.209 & 0.105 & 0.101 & 0.078 & 0.074 & 0.031 & 0.062 & 0.039 & \cellcolor{white}{\textbf{0.558}} & \cellcolor{white}{\textbf{0.565}} & \cellcolor{white}{\textbf{0.770}} & \cellcolor{white}{\textbf{0.470}}\\
\hline
\textbf{2011} & 0.310 & 0.202 & 0.112 & 0.101 & 0.070 & 0.074 & 0.035 & 0.054 & 0.043 & \cellcolor{white}{\textbf{0.827}} & \cellcolor{white}{\textbf{0.739}} & \cellcolor{white}{\textbf{0.670}} & \cellcolor{white}{\textbf{0.382}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 10 : Tests sur la région de Puglia}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.322 & 0.159 & 0.127 & 0.100 & 0.077 & 0.065 & 0.062 & 0.062 & 0.027 & \cellcolor{white}{\textbf{0.788}} & \cellcolor{white}{\textbf{0.329}} & \cellcolor{white}{\textbf{0.801}} & \cellcolor{white}{\textbf{0.562}}\\
\hline
\textbf{2008} & 0.300 & 0.168 & 0.126 & 0.099 & 0.081 & 0.048 & 0.075 & 0.060 & 0.042 & \cellcolor{white}{\textbf{0.836}} & \cellcolor{white}{\textbf{0.451}} & \cellcolor{white}{\textbf{0.966}} & \cellcolor{white}{\textbf{0.822}}\\
\hline
\textbf{2009} & 0.285 & 0.171 & 0.135 & 0.105 & 0.078 & 0.048 & 0.084 & 0.039 & 0.054 & \cellcolor{white}{\textbf{0.436}} & \cellcolor{white}{\textbf{0.991}} & \cellcolor{white}{\textbf{0.889}} & \cellcolor{white}{\textbf{0.655}}\\
\hline
\textbf{2010} & 0.300 & 0.168 & 0.120 & 0.114 & 0.078 & 0.057 & 0.072 & 0.048 & 0.042 & \cellcolor{white}{\textbf{0.935}} & \cellcolor{white}{\textbf{0.534}} & \cellcolor{white}{\textbf{0.922}} & \cellcolor{white}{\textbf{0.968}}\\
\hline
\textbf{2011} & 0.294 & 0.156 & 0.117 & 0.120 & 0.087 & 0.048 & 0.072 & 0.048 & 0.057 & \cellcolor{white}{\textbf{0.538}} & \cellcolor{white}{\textbf{0.861}} & \cellcolor{white}{\textbf{0.736}} & \cellcolor{white}{\textbf{0.437}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 11 : Tests sur la région de Trentino-alto}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.270 & 0.230 & 0.095 & 0.081 & 0.122 & 0.054 & 0.081 & 0.041 & 0.027 & \cellcolor{white}{\textbf{0.708}} & \cellcolor{white}{\textbf{0.633}} & \cellcolor{white}{\textbf{0.728}} & \cellcolor{white}{\textbf{0.902}}\\
\hline
\textbf{2008} & 0.270 & 0.243 & 0.108 & 0.068 & 0.108 & 0.054 & 0.081 & 0.014 & 0.054 & \cellcolor{white}{\textbf{0.563}} & \cellcolor{white}{\textbf{0.806}} & \cellcolor{white}{\textbf{0.939}} & \cellcolor{white}{\textbf{0.825}}\\
\hline
\textbf{2009} & 0.284 & 0.203 & 0.122 & 0.054 & 0.149 & 0.054 & 0.068 & 0.027 & 0.041 & \cellcolor{white}{\textbf{0.486}} & \cellcolor{white}{\textbf{0.606}} & \cellcolor{white}{\textbf{0.799}} & \cellcolor{white}{\textbf{0.870}}\\
\hline
\textbf{2010} & 0.284 & 0.216 & 0.108 & 0.027 & 0.162 & 0.068 & 0.054 & 0.041 & 0.041 & \cellcolor{white}{\textbf{0.185}} & \cellcolor{white}{\textbf{0.645}} & \cellcolor{white}{\textbf{0.923}} & \cellcolor{white}{\textbf{0.983}}\\
\hline
\textbf{2011} & 0.284 & 0.176 & 0.135 & 0.041 & 0.135 & 0.081 & 0.054 & 0.027 & 0.068 & \cellcolor{white}{\textbf{0.501}} & \cellcolor{white}{\textbf{0.984}} & \cellcolor{white}{\textbf{0.908}} & \cellcolor{white}{\textbf{0.654}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 12 : Tests sur la région de Valle D'aosta}
\end{table}

\textbf{Seulement un test}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.287 & 0.195 & 0.123 & 0.077 & 0.085 & 0.079 & 0.051 & 0.049 & 0.054 & \cellcolor{white}{\textbf{0.798}} & \cellcolor{white}{\textbf{0.235}} & \cellcolor{white}{\textbf{0.904}} & \cellcolor{white}{\textbf{0.706}}\\
\hline
\textbf{2008} & 0.272 & 0.205 & 0.123 & 0.077 & 0.082 & 0.069 & 0.067 & 0.044 & 0.062 & \cellcolor{white}{\textbf{0.460}} & \cellcolor{white}{\textbf{0.088}} & \cellcolor{white}{\textbf{0.602}} & \cellcolor{white}{\textbf{0.362}}\\
\hline
\textbf{2009} & 0.279 & 0.203 & 0.123 & 0.077 & 0.079 & 0.072 & 0.064 & 0.051 & 0.051 & \cellcolor{white}{\textbf{0.817}} & \cellcolor{red}{\textbf{0.035}} & \cellcolor{white}{\textbf{0.830}} & \cellcolor{white}{\textbf{0.574}}\\
\hline
\textbf{2010} & 0.282 & 0.197 & 0.131 & 0.074 & 0.085 & 0.056 & 0.079 & 0.038 & 0.056 & \cellcolor{white}{\textbf{0.285}} & \cellcolor{white}{\textbf{0.389}} & \cellcolor{white}{\textbf{0.845}} & \cellcolor{white}{\textbf{0.631}}\\
\hline
\textbf{2011} & 0.290 & 0.195 & 0.126 & 0.079 & 0.077 & 0.067 & 0.069 & 0.038 & 0.059 & \cellcolor{white}{\textbf{0.674}} & \cellcolor{white}{\textbf{0.172}} & \cellcolor{white}{\textbf{0.793}} & \cellcolor{white}{\textbf{0.737}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 13 : Tests sur la région de la Sicilia}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.310 & 0.165 & 0.136 & 0.117 & 0.057 & 0.057 & 0.062 & 0.040 & 0.057 & \cellcolor{white}{\textbf{0.184}} & \cellcolor{white}{\textbf{0.172}} & \cellcolor{white}{\textbf{0.770}} & \cellcolor{white}{\textbf{0.714}}\\
\hline
\textbf{2008} & 0.313 & 0.167 & 0.139 & 0.107 & 0.062 & 0.062 & 0.065 & 0.041 & 0.043 & \cellcolor{white}{\textbf{0.619}} & \cellcolor{white}{\textbf{0.268}} & \cellcolor{white}{\textbf{0.666}} & \cellcolor{white}{\textbf{0.374}}\\
\hline
\textbf{2009} & 0.320 & 0.170 & 0.138 & 0.105 & 0.062 & 0.064 & 0.062 & 0.043 & 0.036 & \cellcolor{white}{\textbf{0.613}} & \cellcolor{white}{\textbf{0.408}} & \cellcolor{white}{\textbf{0.316}} & \cellcolor{white}{\textbf{0.139}}\\
\hline
\textbf{2010} & 0.325 & 0.172 & 0.138 & 0.103 & 0.067 & 0.062 & 0.055 & 0.053 & 0.024 & \cellcolor{white}{\textbf{0.297}} & \cellcolor{white}{\textbf{0.527}} & \cellcolor{white}{\textbf{0.094}} & \cellcolor{red}{\textbf{0.042}}\\
\hline
\textbf{2011} & 0.322 & 0.170 & 0.134 & 0.105 & 0.071 & 0.057 & 0.060 & 0.048 & 0.033 & \cellcolor{white}{\textbf{0.704}} & \cellcolor{white}{\textbf{0.763}} & \cellcolor{white}{\textbf{0.270}} & \cellcolor{white}{\textbf{0.118}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 14 : Tests sur la région de Veneto}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.309 & 0.160 & 0.096 & 0.094 & 0.067 & 0.102 & 0.051 & 0.054 & 0.067 & \cellcolor{red}{\textbf{0.006}} & \cellcolor{white}{\textbf{0.201}} & \cellcolor{red}{\textbf{0.026}} & \cellcolor{white}{\textbf{0.063}}\\
\hline
\textbf{2008} & 0.314 & 0.160 & 0.093 & 0.100 & 0.065 & 0.100 & 0.044 & 0.062 & 0.064 & \cellcolor{red}{\textbf{0.003}} & \cellcolor{white}{\textbf{0.404}} & \cellcolor{red}{\textbf{0.034}} & \cellcolor{white}{\textbf{0.114}}\\
\hline
\textbf{2009} & 0.310 & 0.176 & 0.091 & 0.091 & 0.071 & 0.093 & 0.051 & 0.060 & 0.058 & \cellcolor{white}{\textbf{0.068}} & \cellcolor{white}{\textbf{0.090}} & \cellcolor{white}{\textbf{0.096}} & \cellcolor{white}{\textbf{0.236}}\\
\hline
\textbf{2010} & 0.310 & 0.172 & 0.091 & 0.087 & 0.082 & 0.087 & 0.049 & 0.065 & 0.056 & \cellcolor{white}{\textbf{0.094}} & \cellcolor{white}{\textbf{0.069}} & \cellcolor{white}{\textbf{0.089}} & \cellcolor{white}{\textbf{0.186}}\\
\hline
\textbf{2011} & 0.310 & 0.172 & 0.087 & 0.083 & 0.087 & 0.078 & 0.060 & 0.058 & 0.064 & \cellcolor{white}{\textbf{0.101}} & \cellcolor{red}{\textbf{0.007}} & \cellcolor{red}{\textbf{0.024}} & \cellcolor{white}{\textbf{0.106}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}


\caption{Tableau 15 : Tests sur la région de Campania}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.296 & 0.201 & 0.103 & 0.078 & 0.069 & 0.069 & 0.057 & 0.066 & 0.060 & \cellcolor{white}{\textbf{0.482}} & \cellcolor{red}{\textbf{0.010}} & \cellcolor{white}{\textbf{0.132}} & \cellcolor{white}{\textbf{0.398}}\\
\hline
\textbf{2008} & 0.310 & 0.204 & 0.101 & 0.080 & 0.066 & 0.066 & 0.060 & 0.063 & 0.049 & \cellcolor{white}{\textbf{0.634}} & \cellcolor{red}{\textbf{0.035}} & \cellcolor{white}{\textbf{0.311}} & \cellcolor{white}{\textbf{0.979}}\\
\hline
\textbf{2009} & 0.305 & 0.201 & 0.103 & 0.072 & 0.075 & 0.060 & 0.060 & 0.060 & 0.063 & \cellcolor{white}{\textbf{0.430}} & \cellcolor{red}{\textbf{0.005}} & \cellcolor{white}{\textbf{0.090}} & \cellcolor{white}{\textbf{0.574}}\\
\hline
\textbf{2010} & 0.290 & 0.201 & 0.112 & 0.072 & 0.072 & 0.055 & 0.066 & 0.063 & 0.069 & \cellcolor{white}{\textbf{0.225}} & \cellcolor{red}{\textbf{0.019}} & \cellcolor{red}{\textbf{0.044}} & \cellcolor{white}{\textbf{0.250}}\\
\hline
\textbf{2011} & 0.299 & 0.195 & 0.115 & 0.072 & 0.060 & 0.069 & 0.063 & 0.072 & 0.055 & \cellcolor{white}{\textbf{0.384}} & \cellcolor{red}{\textbf{0.019}} & \cellcolor{white}{\textbf{0.128}} & \cellcolor{white}{\textbf{0.423}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 16 : Tests sur la région d'Emilia-romagna}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.272 & 0.209 & 0.085 & 0.089 & 0.077 & 0.098 & 0.043 & 0.047 & 0.081 & \cellcolor{red}{\textbf{0.044}} & \cellcolor{white}{\textbf{0.078}} & \cellcolor{white}{\textbf{0.172}} & \cellcolor{white}{\textbf{0.148}}\\
\hline
\textbf{2008} & 0.268 & 0.213 & 0.089 & 0.081 & 0.055 & 0.111 & 0.055 & 0.034 & 0.094 & \cellcolor{red}{\textbf{0.001}} & \cellcolor{white}{\textbf{0.597}} & \cellcolor{red}{\textbf{0.044}} & \cellcolor{white}{\textbf{0.073}}\\
\hline
\textbf{2009} & 0.294 & 0.209 & 0.077 & 0.098 & 0.060 & 0.094 & 0.060 & 0.034 & 0.077 & \cellcolor{red}{\textbf{0.047}} & \cellcolor{white}{\textbf{0.106}} & \cellcolor{white}{\textbf{0.267}} & \cellcolor{white}{\textbf{0.418}}\\
\hline
\textbf{2010} & 0.289 & 0.196 & 0.094 & 0.102 & 0.047 & 0.094 & 0.072 & 0.030 & 0.077 & \cellcolor{red}{\textbf{0.043}} & \cellcolor{white}{\textbf{0.570}} & \cellcolor{white}{\textbf{0.285}} & \cellcolor{white}{\textbf{0.320}}\\
\hline
\textbf{2011} & 0.306 & 0.191 & 0.089 & 0.115 & 0.047 & 0.089 & 0.060 & 0.043 & 0.060 & \cellcolor{white}{\textbf{0.286}} & \cellcolor{white}{\textbf{0.246}} & \cellcolor{white}{\textbf{0.650}} & \cellcolor{white}{\textbf{0.800}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 17 : Tests sur la région de la Liguria}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.268 & 0.172 & 0.092 & 0.121 & 0.084 & 0.063 & 0.054 & 0.071 & 0.075 & \cellcolor{white}{\textbf{0.199}} & \cellcolor{white}{\textbf{0.108}} & \cellcolor{red}{\textbf{0.049}} & \cellcolor{red}{\textbf{0.026}}\\
\hline
\textbf{2008} & 0.285 & 0.172 & 0.092 & 0.113 & 0.084 & 0.071 & 0.059 & 0.054 & 0.071 & \cellcolor{white}{\textbf{0.593}} & \cellcolor{white}{\textbf{0.163}} & \cellcolor{white}{\textbf{0.208}} & \cellcolor{white}{\textbf{0.122}}\\
\hline
\textbf{2009} & 0.280 & 0.180 & 0.088 & 0.117 & 0.088 & 0.071 & 0.067 & 0.042 & 0.067 & \cellcolor{white}{\textbf{0.497}} & \cellcolor{white}{\textbf{0.139}} & \cellcolor{white}{\textbf{0.420}} & \cellcolor{white}{\textbf{0.200}}\\
\hline
\textbf{2010} & 0.285 & 0.180 & 0.096 & 0.096 & 0.109 & 0.054 & 0.071 & 0.038 & 0.071 & \cellcolor{white}{\textbf{0.269}} & \cellcolor{white}{\textbf{0.473}} & \cellcolor{white}{\textbf{0.429}} & \cellcolor{white}{\textbf{0.239}}\\
\hline
\textbf{2011} & 0.293 & 0.197 & 0.088 & 0.096 & 0.105 & 0.042 & 0.071 & 0.054 & 0.054 & \cellcolor{white}{\textbf{0.376}} & \cellcolor{white}{\textbf{0.501}} & \cellcolor{white}{\textbf{0.716}} & \cellcolor{white}{\textbf{0.567}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 18 : Tests sur la région de Marche}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.243 & 0.125 & 0.191 & 0.118 & 0.074 & 0.074 & 0.074 & 0.051 & 0.051 & \cellcolor{white}{\textbf{0.284}} & \cellcolor{white}{\textbf{0.175}} & \cellcolor{white}{\textbf{0.165}} & \cellcolor{white}{\textbf{0.162}}\\
\hline
\textbf{2008} & 0.221 & 0.110 & 0.213 & 0.118 & 0.059 & 0.103 & 0.044 & 0.074 & 0.059 & \cellcolor{red}{\textbf{0.007}} & \cellcolor{white}{\textbf{0.923}} & \cellcolor{red}{\textbf{0.047}} & \cellcolor{red}{\textbf{0.033}}\\
\hline
\textbf{2009} & 0.250 & 0.110 & 0.184 & 0.110 & 0.081 & 0.103 & 0.051 & 0.066 & 0.044 & \cellcolor{white}{\textbf{0.156}} & \cellcolor{white}{\textbf{0.860}} & \cellcolor{white}{\textbf{0.110}} & \cellcolor{white}{\textbf{0.116}}\\
\hline
\textbf{2010} & 0.228 & 0.132 & 0.169 & 0.118 & 0.096 & 0.081 & 0.066 & 0.037 & 0.074 & \cellcolor{white}{\textbf{0.233}} & \cellcolor{white}{\textbf{0.543}} & \cellcolor{white}{\textbf{0.079}} & \cellcolor{white}{\textbf{0.051}}\\
\hline
\textbf{2011} & 0.235 & 0.140 & 0.169 & 0.096 & 0.103 & 0.081 & 0.081 & 0.029 & 0.066 & \cellcolor{white}{\textbf{0.252}} & \cellcolor{white}{\textbf{0.219}} & \cellcolor{white}{\textbf{0.117}} & \cellcolor{white}{\textbf{0.087}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 19 : Tests sur la région de Molise}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.310 & 0.167 & 0.093 & 0.053 & 0.050 & 0.119 & 0.064 & 0.109 & 0.034 & \cellcolor{red}{\textbf{0.000}} & \cellcolor{white}{\textbf{0.761}} & \cellcolor{red}{\textbf{0.010}} & \cellcolor{red}{\textbf{0.000}}\\
\hline
\textbf{2008} & 0.310 & 0.172 & 0.095 & 0.106 & 0.069 & 0.093 & 0.077 & 0.024 & 0.053 & \cellcolor{red}{\textbf{0.048}} & \cellcolor{white}{\textbf{0.659}} & \cellcolor{white}{\textbf{0.956}} & \cellcolor{white}{\textbf{0.772}}\\
\hline
\textbf{2009} & 0.316 & 0.175 & 0.101 & 0.095 & 0.085 & 0.069 & 0.093 & 0.032 & 0.034 & \cellcolor{white}{\textbf{0.084}} & \cellcolor{white}{\textbf{0.476}} & \cellcolor{white}{\textbf{0.825}} & \cellcolor{white}{\textbf{0.741}}\\
\hline
\textbf{2010} & 0.318 & 0.175 & 0.095 & 0.090 & 0.093 & 0.061 & 0.095 & 0.034 & 0.037 & \cellcolor{red}{\textbf{0.042}} & \cellcolor{white}{\textbf{0.129}} & \cellcolor{white}{\textbf{0.962}} & \cellcolor{white}{\textbf{0.816}}\\
\hline
\textbf{2011} & 0.314 & 0.174 & 0.103 & 0.087 & 0.092 & 0.066 & 0.103 & 0.029 & 0.032 & \cellcolor{red}{\textbf{0.006}} & \cellcolor{white}{\textbf{0.832}} & \cellcolor{white}{\textbf{0.860}} & \cellcolor{white}{\textbf{0.880}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 20 : Tests sur la région de la Sardegna}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.331 & 0.188 & 0.125 & 0.059 & 0.066 & 0.070 & 0.035 & 0.059 & 0.066 & \cellcolor{white}{\textbf{0.171}} & \cellcolor{white}{\textbf{0.112}} & \cellcolor{red}{\textbf{0.045}} & \cellcolor{red}{\textbf{0.013}}\\
\hline
\textbf{2008} & 0.328 & 0.195 & 0.105 & 0.080 & 0.070 & 0.059 & 0.042 & 0.059 & 0.063 & \cellcolor{white}{\textbf{0.526}} & \cellcolor{white}{\textbf{0.169}} & \cellcolor{white}{\textbf{0.086}} & \cellcolor{white}{\textbf{0.713}}\\
\hline
\textbf{2009} & 0.321 & 0.206 & 0.094 & 0.084 & 0.073 & 0.056 & 0.038 & 0.066 & 0.063 & \cellcolor{white}{\textbf{0.255}} & \cellcolor{white}{\textbf{0.087}} & \cellcolor{white}{\textbf{0.080}} & \cellcolor{white}{\textbf{0.841}}\\
\hline
\textbf{2010} & 0.341 & 0.195 & 0.101 & 0.084 & 0.066 & 0.059 & 0.042 & 0.045 & 0.066 & \cellcolor{white}{\textbf{0.346}} & \cellcolor{white}{\textbf{0.184}} & \cellcolor{red}{\textbf{0.043}} & \cellcolor{white}{\textbf{0.358}}\\
\hline
\textbf{2011} & 0.369 & 0.185 & 0.101 & 0.091 & 0.073 & 0.042 & 0.056 & 0.038 & 0.045 & \cellcolor{white}{\textbf{0.280}} & \cellcolor{white}{\textbf{0.563}} & \cellcolor{red}{\textbf{0.023}} & \cellcolor{red}{\textbf{0.030}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 21 : Tests sur la région de Toscana}
\end{table}

\begin{table}

\begin{table}[H]
\centering\begingroup\fontsize{10}{12}\selectfont

\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\fontsize{10}{12}\selectfont
\begin{tabular}{>{}r|r|r|r|r|r|r|r|r|r|>{}r|>{}r|>{}r|>{}r}
\hline
\multicolumn{1}{c|}{\textbf{Année}} & \multicolumn{9}{c|}{\textbf{Chiffre significatif}} & \multicolumn{4}{c}{\textbf{p-value}} \\
\cline{1-1} \cline{2-10} \cline{11-14}
  & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & $\chi^2$ & $Freedman$ & $T_2$ & $T_{\hat{K}}$\\
\hline
\textbf{2007} & 0.38 & 0.207 & 0.130 & 0.065 & 0.109 & 0.054 & 0.011 & 0.022 & 0.022 & \cellcolor{white}{\textbf{0.210}} & \cellcolor{white}{\textbf{0.786}} & \cellcolor{red}{\textbf{0.030}} & \cellcolor{red}{\textbf{0.021}}\\
\hline
\textbf{2008} & 0.37 & 0.207 & 0.130 & 0.065 & 0.120 & 0.043 & 0.022 & 0.022 & 0.022 & \cellcolor{white}{\textbf{0.241}} & \cellcolor{white}{\textbf{0.426}} & \cellcolor{white}{\textbf{0.052}} & \cellcolor{red}{\textbf{0.025}}\\
\hline
\textbf{2009} & 0.37 & 0.207 & 0.130 & 0.076 & 0.120 & 0.043 & 0.022 & 0.022 & 0.011 & \cellcolor{white}{\textbf{0.196}} & \cellcolor{white}{\textbf{0.701}} & \cellcolor{red}{\textbf{0.022}} & \cellcolor{red}{\textbf{0.017}}\\
\hline
\textbf{2010} & 0.37 & 0.217 & 0.120 & 0.076 & 0.109 & 0.065 & 0.011 & 0.000 & 0.033 & \cellcolor{white}{\textbf{0.136}} & \cellcolor{white}{\textbf{0.871}} & \cellcolor{red}{\textbf{0.035}} & \cellcolor{red}{\textbf{0.019}}\\
\hline
\textbf{2011} & 0.38 & 0.217 & 0.109 & 0.087 & 0.109 & 0.054 & 0.011 & 0.011 & 0.022 & \cellcolor{white}{\textbf{0.154}} & \cellcolor{white}{\textbf{0.683}} & \cellcolor{red}{\textbf{0.018}} & \cellcolor{red}{\textbf{0.013}}\\
\hline
\end{tabular}
\endgroup{}
\end{table}

\caption{Tableau 22 : Tests sur la région de Umbria}
\end{table}

\hypertarget{cas-covid}{%
\subsection{CAS COVID}\label{cas-covid}}

~ La crise du COVID-\(19\) étant au coeur des débats actuels et ayant un
impact non négligeable sur notre scolarité, nous avons voulu nous
intéresser aux chiffres que la Chine a publié. La Chine, à l'origine du
départ de cette pandémie à publié des données sur l'expansion des cas
dans son territoire. Un article écrit par Junyi Zhang qui recense le
nombre de cas de personne atteinte du Covid-\(19\) en Chine et compare
la répartition des premiers chiffres significatifs avec la loi de
Newcomb-Benford. D'après cet article le test qui teste l'hypothèse nulle
``les données diffusées par la Chine suivent la loi de Newcomb-Benford''
contre l'hypothèse alternative ``les données diffusées par la Chine ne
suivent pas la loi de Newcomb-Benford'' donne une \(p\)-value de
\(92.8 \%\). Pour confirmer le résultat, Ducharme et ses collaborateurs
ont utilisé les mêmes données pour appliquer des tests avec les mêmes
hypothèses. Malheureusement cela ne collait pas avec les résultats
attendus. Nous-mêmes nous sommes allées chercher les données de cet
article, mais le lien des données n'existe plus sur Wikipédia. On peut
donc penser que les données ne sont pas cohérentes ou qu'il y a eu une
erreur dans son étude ou fraude sur les chiffres.

\newpage

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

~ Au cours de ce projet, nous avons pu acquérir de nouvelles
connaissances, ce fut intéressant et enrichissant de réaliser nos
propres expériences et de nous initier au vaste problème de la détection
de fraudes. Nous avons tenté de répondre à certaines questions : quelle
répartition suit le premier chiffre significatif d'une suite de nombres
générés naturellement ? Les tests mis en place pour détecter une fraude
sont-ils fiables et vont-ils toujours dans le même sens ? Certains
sont-ils meilleurs que d'autres ?

Nous avons pu voir que dans certains cas le premier chiffre peut suivre
la loi de Newcomb-Benford, loi que nous avons découverte au cours de ce
projet en exposant sa genèse, mais aussi en l'étudiant au travers de
différents tests.

Dans la suite de ce projet, nous avons appris que la détection de
fraudes était délicate. En effet, nous avons remarqué que la loi de
Newcomb-Benford ne s'applique pas systématiquement à toutes les données.
Comme nous l'avons découvert dans l'expérience de Hill ainsi que lorsque
nous l'avons reproduite à moindre échelle, les données influencées par
la pensée humaine ne suivent généralement pas la loi de Newcomb-Benford.
De plus, les données dites naturelles auront moins tendance à suivre la
loi de Newcomb-Benford si celles-ci sont brutes.\\
Une observation visuelle n'étant que peu efficace, nous avons réalisé
différents tests. Notons que la réalisation d'un test n'est pas
complètement fiable, et qu'il faut tenir compte des risques d'erreurs,
le risque de suspecter à tort une fraude et le risque de laisser passer
une fraude.

Il est également important de retenir que le risque de lancer un audit
pour suspicion de fraude peut coûter cher, plus cher que le risque de
laisser passer une fraude.

Lors de l'application des tests, nous avons remarqué que certains tests
avaient mené à une suspicion de fraude, d'autre pas. Les tests sont
rarement unanimes, cela vient du fait qu'ils sont performants pour des
types de fraudes différents. Un test sera plus susceptible de mettre en
évidence une manière de frauder qu'une autre. Ceci encourage
l'utilisation de plusieurs tests, il n'y a donc pas vraisemblablement de
meilleur test, cependant un test peut couvrir un plus large éventail de
fraude.

La loi de Newcomb-Benford ne s'applique pas qu'au premier chiffre
significatif, pour avoir un autre point de vue, il serait bien
d'appliquer la loi de Newcomb-Benford sur le deuxième chiffre
significatif et lui appliquer les différents tests. Ceci pourrait mener
à une autre conclusion ?

\newpage

\hypertarget{bibliographie}{%
\section{Bibliographie}\label{bibliographie}}

\textbf{\underline{Génèse de la loi}} :

V. GENEST, C. GENEST \emph{La loi de Newcomb-Benford ou la loi du
premier chiffre significatif} (\(2011\))
(\href{https://accromath.uqam.ca/wp-content/uploads/2019/10/Benford.pdf}{\emph{Source}})

WIKIPEDIA L'ENCYCLOPEDIE LIBRE \emph{Loi de Benford} (dernière mise à
jour \(2021\))
(\href{https://fr.wikipedia.org/wiki/Loi_de_Benford}{\emph{Source}})

T. P. HILL \emph{Random-number guessing and the first digit phenomenon}
(\(1988\))
(\href{https://hill.math.gatech.edu/publications/PAPER\%20PDFS/RandomNumberGuessing_Hill_88.pdf}{\emph{Source}})

\medskip

\textbf{\underline{Test d'hypothèses}} :

G. R. DUCHARME, S. KACI, C. VOVOR-DASSU \emph{Tests d'adéquations lisses
pour la loi de Newcomb-Benford} (\(2020\))
(\href{https://www.researchgate.net/publication/339641985_Smooths_Tests_of_Goodness-of-fit_for_the_Newcomb-Benford_distribution}{\emph{Source}})

LENOIR \emph{Les tests d'hypothèses}
(\href{https://www.imo.universite-paris-saclay.fr/~pansu/web_ifips/Tests.pdf}{\emph{Source}})

MINITAB \emph{Tests d'hypothèses}
\href{https://support.minitab.com/fr-fr/minitab/20/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/what-is-a-hypothesis-test/}{\emph{Source}})

WIKIPEDIA L'ENCYCLOPEDIE LIBRE \emph{Test statistique} (dernière mise à
jour \(2021\))
(\href{https://fr.wikipedia.org/wiki/Test_statistique}{\emph{Source}})

J. J. RUCH \emph{Statistique : Tests d'hypothèses} (\(2012/2013\))
(\href{https://www.math.u-bordeaux.fr/~mchabano/Agreg/ProbaAgreg1213-COURS3-Stat2.pdf}{\emph{Source}})\\
\medskip

\textbf{\underline{Khi-deux}} :

BIBMATH \emph{Loi du Khi-deux}
(\href{http://www.bibmath.net/dico/index.php?action=affiche\&quoi=./l/loichideux.html}{\emph{Source}})

WIKIPEDIA L'ENCYCLOPEDIE LIBRE \emph{Test du Khi-deux de Pearson}
(dernière mise à jour \(2021\))
(\href{https://fr.wikipedia.org/wiki/Test_du_\%CF\%87\%C2\%B2\#Test_du_\%CF\%872_de_Pearson}{\emph{Source}})

BIBMATH \emph{Tests du Khi-deux}
(\href{http://www.bibmath.net/dico/index.php?action=affiche\&quoi=./c/chideuxtest.html}{\emph{Source}})

WIKIMEDIA COMMONS \emph{Khi-deux}
(\href{https://commons.wikimedia.org/wiki/File:Chi-square_pdf.svg?uselang=fr}{\emph{Source}})

\medskip

\textbf{\underline{Freedman}} :

D. JOENSSEN, T. MUELLERLEILE \emph{Package R ``BenfordTest''} (\(2015\))
(\href{https://cran.r-project.org/web/packages/BenfordTests/BenfordTests.pdf}{\emph{Source}})

D. JOENSSEN \emph{Testing for Benford's Law: A Monte Carlo Comparison of
Methods} (\(2014\))
(\href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2545243}{\emph{Source}})

LESPERANCE M., REED W.J., STEPHENS M.A., TSAO C., WILTON B.,
\emph{Assessing conformance with Benford's law : Goodness-ff-fit fets
and simultaneous confidence interval} (\(2016\))
(\href{https://storage.googleapis.com/plos-corpus-prod/10.1371/journal.pone.0151235/1/pone.0151235.pdf?X-Goog-Algorithm=GOOG4-RSA-SHA256\&X-Goog-Credential=wombat-sa\%40plos-prod.iam.gserviceaccount.com\%2F20210522\%2Fauto\%2Fstorage\%2Fgoog4_request\&X-Goog-Date=20210522T115455Z\&X-Goog-Expires=86400\&X-Goog-SignedHeaders=host\&X-Goog-Signature=15ee92de490a5ad03c0a988bd684e565f8f4c27b54c41baa8ad1f65a4797da38755fbeb5cb9de7015d9e116b4d6a48826faf7bbc830ddc22081a55d5e79c96b16ccf18034b8f5db6eea250cee093045800e9ebb0ad6aa045b152178a9741233648a79ed1392573d541c5c7f765210a0842dfcfbe92fde5458e42d450a1f10d41754197e86c01b09fdae2629cce26e69754feafb6209114ae9a8cad08dfd2698e1353fd67a0f8c4afd2b265cbade44accd33bc6b3661d086b6ab1c4996e7273a1577f39076d29d1f45cf113aaa2a4ce0800de08b9e4be80a12f7fc67a2c0d2861a3439255425e3cbdc181dfb8cdb54612070e49570d433ff6f1304d8d33afbaf5}{\emph{Source}})

\medskip

\textbf{\underline{Test lisse}} :

B. BOULERICE, G.R. DUCHARME \emph{Smooth test of goodness-of-fit for
directional and axial data}, Journal Multivariate Analysis 60 : 154-175
(\(1997\))
(\href{https://core.ac.uk/download/pdf/82062058.pdf}{\emph{Source}})

G.R. DUCHARME, S. KACI, C. VOVOR-DASSU article \emph{Tests d'adéquations
lisse pour la loi de Newcomb-Benford} (\(2020\))
(\href{https://www.researchgate.net/publication/339641985_Smooths_Tests_of_Goodness-of-fit_for_the_Newcomb-Benford_distribution\%5D}{\emph{Source}})

G.R. DUCHARME, S. KACI, C. VOVOR-DASSU \emph{BenfordSmoothTest}
(\(2020\))
(\href{https://github.com/st-homme/benfordSmoothTest}{\emph{Source}})

NEYMAN J. \emph{Smooth tests for goodnesss-of-fit}, Skand.
Aktuariedidskr \(20\) : \(150 - 199\) (\(1937\))

\medskip

\textbf{\underline{Cas fiscalité italienne}} :

MARCEL AUSLOOS, ROY CERQUETI, TARIC A. MIR \emph{Data science for
assessing possible tax incomemanipulation: the case of Italy} (\(2017\))
(\href{https://arxiv.org/pdf/1709.02129.pdf}{\emph{Source}})

\textbf{\underline{Cas Covid-$19$}} :

JUNYI ZHAN \emph{Testing Case Number of Coronavirus Disease 2019 in
China with Newcomb-Benford Law} (\(2020\))
(\href{https://arxiv.org/abs/2002.05695\%5D}{\emph{Source}})

\end{document}
